% Copyright 2005-2016 Airbus-EDF-IMACS-Phimeca
% Permission is granted to copy, distribute and/or modify this document
% under the terms of the GNU Free Documentation License, Version 1.2
% or any later version published by the Free Software Foundation;
% with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
% Texts.  A copy of the license is included in the section entitled "GNU
% Free Documentation License".
\renewcommand{\filename}{docUC_InputWithData_BayesianCalibration.tex}
\renewcommand{\filetitle}{UC : Bayesian Calibration of a Computer Code}

% \HeaderNNIILevel
% \HeaderIILevel
\HeaderIIILevel



% \index{Fitting Distribution! Maximum likelihood}


The objective of this Use Case is to explicitate how to implement the evaluation of the parameters of a computer model thanks to Bayesian estimation.\\


Details on the Principle of Bayesian Calibration may be found in the Reference Guide (\extref{ReferenceGuide}{see files Reference Guide - Step B -- Bayesian Calibration}{stepB}).\\

Let us denote $\vect y = (y_1, \dots, y_n)$ the observation sample, $\vect z = (f(x_1|\vect{\theta}), \ldots, f(x_n|\vect{\theta}))$ the model prediction, $p(y |z)$ the density function of observation $y$ conditional on model prediction $z$, and $\vect{\theta} \in \Rset^p$ the calibration parameters we wish to estimate.\\

The following objects need to be defined in order to perform Bayesian calibration with Open-TURNS:

\begin{itemize}
\item the conditional density $p(y|z)$ must be defined as a probability distribution, as explained in the UC.% je ne sais comment trouver la reference pour le UC Usual Distributions
\item The computer model must be implemented thanks to the NumericalMathFunction class, as explained in the section \ref{sec:LSFcreation}. This takes a value of $\vect{\theta}$ as input, and outputs the vector of model predictions $\vect z$, as defined above (the vector of covariates $\vect x = (x_1, \ldots, x_n)$ is treated as a known constant). When doing that, we have to keep in mind that $z$ will be used as the vector of parameters corresponding to the distribution specified for $p(y |z)$. For instance, if $p(y|z)$ is normal, this means that $z$ must be a vector containing the mean and variance of $y$ (see the example below)
\item the prior density $\pi(\vect{\theta})$ encoding the set of possible values for the calibration parameters, each value being weighted by its {\em a priori} proabibility, reflecting the beliefs about the possible values of $\vect{\theta}$ before consideration of the experimental data. Again, this is implemented as a probability distribution
\item The Metropolis-Hastings algorithm that samples from the posterior distribution of the calibration parameters requires a vector $\vect{\theta}_0$ initial values for the calibration parameters, as well as the proposal laws used to update each parameter sequentially.
\end{itemize}

The posterior distribution is given by Bayes' theorem :
\begin{align*}
  \pi(\vect{\theta} | \vect y)
  \quad \substack{~\\[0.5em]\displaystyle\propto\\\scriptstyle\vect{\theta}} \quad
  L\left(\vect y | \vect{\theta}\right) \times \pi(\vect{\theta})
\end{align*}
(where $\substack{~\\[0.5em]\displaystyle\propto\\\scriptstyle\vect{\theta}}$
means "proportional to", regarded as a function of $\vect{\theta}$)
and is approximated here by the empirical distribution of the sample $\vect{\theta}^1, \ldots, \vect{\theta}^N$ generated by the Metropolis-Hastings algorithm. This means that any quantity characteristic of the posterior distribution (mean, variance, quantile, \ldots) is approximated by its empirical counterpart.

The following UC illustrates the example of a standard normal linear regression, where
\begin{align*}
  y_i = \theta_1 + x_i \theta_2 + x_i^2 \theta_3 + \varepsilon_i,
\end{align*}
where $\varepsilon_i \stackrel{i.i.d.}{\sim} \mathcal N(0, 1)$
and we use a normal prior on $\vect{\theta}$:
\begin{align*}
  \pi(\vect{\theta}) = \mathcal N(0 ; 100 I_3).
\end{align*}

The UC is divided into two Python scripts:
\begin{itemize}
\item the first one shows how to define the requirements of the second
  according to the normal linear regression example above (it provides
  some data);
\item the second illustrates how carrying out a Bayesian calibration
  in a general context using the RandomWalkMetropolisHastings class.
\end{itemize}

First Python script for this UseCase:

\inputscript{script_docUC_InputWithData_BayesianCalibration1}

\newpage

Second Python script for this UseCase :

\requirements{
  \begin{description}
  \item[$\bullet$] a prior distribution: {\itshape prior}
  \item[type:]  a Distribution
  \item[$\bullet$] a conditional distribution: {\itshape conditional}
  \item[type:]  a Distribution
  \item[$\bullet$] a model: {\itshape model}
  \item[type:]  a NumericalMathFunction
  \item[$\bullet$] a sample of data: {\itshape y\_obs}
  \item[type:]  a NumericalSample
  \end{description}
}
             {
               \begin{description}
               \item[$\bullet$] a Random Walk Metropolis-Hastings (RWMH) sampler: {\itshape RWMHsampler}
               \item[type:] a RandomWalkMetropolisHastings
               \item[$\bullet$] a posterior random vector: {\itshape myRandomVector}
               \item[type:] a PosteriorRandomVector
               \end{description}
             }

             \inputscript{script_docUC_InputWithData_BayesianCalibration2}
